#! /usr/bin/env node
var Docker        = require('dockerode-promise');
var Capacity      = require('../capacity');
var Worker        = require('../worker');
var metadata      = require('../metadata');
var TaskConsumer  = require('../taskconsumer');
var program       = require('commander');
var os            = require('os');
var dockerOpts    = require('dockerode-options');
var debug         = require('debug')('taskcluster-docker-worker:cli');
var spawn         = require('child_process').spawn;
var Promise       = require('promise');

// one GB in bytes
var DEFAULT_RAM_PER_WORKER = 1073741824;

// default interval to poll for more work when not at capcity (30s)
var DEFAULT_INTERVAL = 30000;

/**
 * Minimum number of minutes left in billing cycle before shutting down.
 *
 * As we estimate our location in the current billing cycle using system uptime
 * There is a reasonable chance that `uptimeInMinutes % 60 == 0` means that the
 * next billing cycle have started. It usually takes a few minutes from instance
 * is launched to it actually starts running. It may also take a few minutes
 * from we initiate shutdown until Amazon EC2 notices that the instance has
 * halted.
 *
 * We should experiment with this number.
 */
var SHUTDOWN_MIN_CYCLE_LEFT = 2;

/**
 * Maximum number of minutes left in billing cycle when shutting down
 *
 * We don't want to shutdown if we have more than this number of minutes left
 * in the current billing cycle. On the other hand, if we set this number too
 * low than we won't always manage to shutdown before the next billing cycle
 * starts.
 *
 * We should play chicken with EC2 and find out what the best number is.
 */
var SHUTDOWN_MAX_CYCLE_LEFT = 12;

/**
 * Default provisionerId for this worker, all workers started on aws by the
 * aws-provisioner should have the provisionerId 'aws-provisioner'.
 *
 * Tasks will be routed to worker based on provisionerId, so this is important.
 */
var DEFAULT_PROVISIONER_ID = 'aws-provisioner';

/**
Determine the overall capacity of the worker based on the RAM of this machine.

XXX: This has a major flaw of getting available memory from the node process
     instead of the docker host which may be on a different machine in the
     future.
*/
function determineCapacity(perWorker) {
  // free memory on startup conditions _should_ be a decent guess as to how
  // many parallel tasks we can run. We always need at least one.
  return Math.max(Math.ceil(os.freemem() / perWorker), 1);
}

/**
 * Shutdown the machine, this is useful when working on spot nodes, as they
 * should just shutdown when they go idle
 */
function shutdown() {
  spawn('sudo', ['shutdown', '-h', 'now']);
};

/** Idle handler to shutdown if fully idle and less than */
function onIdleCapacityShutdown(capacity) {
  // Don't shutdown if we're not fully idle
  if (capacity.size > 0) {
    return;
  }

  // Get system uptime in minutes
  var uptimeInMinutes   = os.uptime() / 60;

  // Number of minutes left before next billing cycle
  var billingCycleLeft  = 60 - (uptimeInMinutes % 60)

  // Shutdown if we have been SHUTDOWN_MIN_CYCLE_LEFT and
  // SHUTDOWN_MAX_CYCLE_LEFT minutes left in billing cycle
  if (SHUTDOWN_MIN_CYCLE_LEFT < billingCycleLeft &&
      billingCycleLeft < SHUTDOWN_MAX_CYCLE_LEFT) {
    debug("Shutting due to idle capacity");
    shutdown();
  }
};

program
  .version(require('../package.json').version)
  .command('start')
  .option(
    '-m, --memory <value>',
    'memory per task in bytes',
    DEFAULT_RAM_PER_WORKER
  )
  .option(
    '-i, --interval <value>',
    'interval to poll for new work when not at capacity in ms',
    DEFAULT_INTERVAL
  )
  .option(
    '-c, --capacity <value>',
    'override all other capacity options'
  )
  .option(
    '--provisioner-id <provisioner-id>',
    "provisionerId, defaults 'aws-provisioner'",
    DEFAULT_PROVISIONER_ID
  )
  .option(
    '--worker-type <worker-type>',
    "workerType, defaults to AMI image-id from metadata service"
  )
  .option(
    '--worker-group <worker-group>',
    "workerGroup, defaults to availability zone from metadata service"
  )
  .option(
    '--worker-id <worker-id>',
    "workerId, defaults to instance id from metadata service"
  )
  .option(
    '-s, --shutdown',
    "Shutdown the machine when this process ends, due to errors or idling"
  )
  .description("Launch a worker process")
  .action(function(options) {
    // Provide default workerType using image-id from ec2 metadata service
    if (options.workerType === undefined) {
      options.workerType = metadata.getImageId();
    }

    // Provide default workerGroup using availability-zone from metadata service
    if (options.workerGroup === undefined) {
      options.workerGroup = metadata.getAvailabilityZone();
    }

    // Provide default workerId using instance-id from metadata service
    if (options.workerId === undefined) {
      options.workerId = metadata.getInstanceId();
    }

    // Create Worker for interfacing the queue
    var workerCreated = Promise.all(
      options.provisionerId,
      options.workerType,
      options.workerGroup,
      options.workerId
    ).then(function(results) {
      var provisionerId = results[0];
      var workerType    = results[1];
      var workerGroup   = results[2];
      var workerId      = results[3];
      return new Worker({
        provisionerId:    provisionerId,
        workerType:       workerType,
        workerGroup:      workerGroup,
        workerId:         workerId
      });
    });

    // Determine capacity
    var capacity = new Capacity(options.capacity ||
                                determineCapacity(options.memory));
    var interval = parseInt(options.interval, 10);

    // Create a task consumer
    var consumerCreated = workerCreated.then(function(worker) {
      return new TaskConsumer({
        capacity:   capacity,
        docker:     new Docker(dockerOpts()),
        interval:   interval,
        worker:     worker
      });
    });

    // Start polling and running tasks
    var consumerRunning = consumerCreated.then(function(consumer) {
      consumer.poll();
      if (options.shutdown) {
        consumer.on('idleCapacity', onIdleCapacityShutdown);
      }
    });

    // When consumer is running
    consumerRunning.then(function() {
      console.log(
        'starting worker with %s parallel tasks polling at %s ms intervals',
        capacity.maximumSize,
        interval
      );
    }).catch(function(err) {
      console.log("Failed to start taskconsumer", err);
      if (options.shutdown) {
        shutdown();
      } else {
        process.exit(1);
      }
    });
  });

program.parse(process.argv);
